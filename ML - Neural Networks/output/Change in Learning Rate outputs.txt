Output for difeerent Learning rates.This is Case 1. Please check report 
for different values of learning rates used and different activation functions.

Activation used:sigmoid
Learning Rate:0.05
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.28609505322434836
The final weight vectors are (starting from input to output layers)
[[ 0.22066355 -1.93334199  0.65880795  3.86219328]
 [ 0.94878318 -1.43086976  1.86759328  2.65712308]
 [-0.44541553 -0.82467783 -0.96156597  0.35227143]
 [-2.75884359  2.46276854  3.32382405  1.90025567]
 [-0.1735428  -0.94072146 -0.96510872  3.43899372]
 [-2.4973307  -4.12976654 -0.03452877 -4.37430896]]
[[ 8.63883581 -3.58423929]
 [ 8.66945114 -4.26047702]
 [-7.01007233 -1.17545368]
 [-5.17712947  4.40900904]]
[[-14.58418475]
 [  9.72975262]]
Activation :sigmoid
Test error is:0.2553521246821141


Activation used:sigmoid
Learning Rate:0.01
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.27209018130667906
The final weight vectors are (starting from input to output layers)
[[ 0.52827375 -1.52435228  1.3703176   1.61935658]
 [ 0.63770794 -1.0814882   1.83733736  1.33543933]
 [-0.20334876 -0.47317906 -0.56884591  0.34273968]
 [-0.90798643  2.10048677  3.89056305  2.09606344]
 [-0.7084916  -0.33574783 -0.84117883  1.5122799 ]
 [-1.52594949 -2.66203461  0.58772364 -2.81833489]]
[[ 5.62105899 -2.76953087]
 [ 5.49920922 -3.05025913]
 [-4.8322863   1.57337497]
 [-3.37791067  2.30339654]]
[[-12.11257327]
 [  7.17384146]]
Activation :sigmoid
Test error is:0.2699767967749953


Activation used:tanh
Learning Rate:0.01
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 1.5227995466478044
The final weight vectors are (starting from input to output layers)
[[ 1.03463578e+02 -1.57893106e+01 -6.74743678e+03 -1.34875213e+02]
 [ 7.26615349e+01 -5.65876415e+00 -5.18805362e+03 -7.26062979e+01]
 [ 2.49525505e+01 -2.97990022e+00 -1.74530320e+03 -2.68151544e+01]
 [ 1.27275100e+02 -2.34598776e+01 -8.04036584e+03 -1.36105826e+02]
 [ 6.41352662e+01 -6.01282469e+00 -3.53620050e+03 -1.60079139e+01]
 [ 1.31847380e+02 -2.57082563e+01 -9.23532798e+03 -2.32019124e+02]]
[[ 16.79118879  45.07228909]
 [ 13.18729602  25.27988258]
 [-20.45000045 -55.94452457]
 [-15.8584103  -39.25275775]]
[[ 0.17206559]
 [13.61752499]]
Activation :tanh
Test error is:0.45538221646415655


Activation used:relu
Learning Rate:0.01
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.5057801609057405
The final weight vectors are (starting from input to output layers)
[[ 0.654272   -0.00834721 -0.27302263 -0.44879379]
 [ 0.84948163 -0.22602153 -0.01423825 -0.4911238 ]
 [ 0.76993304 -0.23347309 -0.40485057  0.43518992]
 [-0.61826011 -0.76361474  0.67399556  0.48827184]
 [ 0.1810411  -0.51421685  0.24649429  0.27671064]
 [-0.34486111 -0.86502131  0.7610772  -0.08008654]]
[[ 0.52774544 -0.49222276]
 [ 0.18277436 -0.14240968]
 [-0.23579871 -0.74657323]
 [-0.51146667 -0.84131683]]
[[-0.39428339]
 [ 0.4834096 ]]
Activation :relu
Test error is:0.48717140882060417

Activation used:sigmoid
Learning Rate:0.1
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.35268085822785206
The final weight vectors are (starting from input to output layers)
[[  0.35036678  -4.77353411   7.18238375   2.137739  ]
 [  2.45226534  -2.38509253   8.01568632   1.27193925]
 [ -0.14612766  -1.46922627   1.00112723   0.91884626]
 [ -9.38778285  -0.28996208  -0.94777496   5.77484436]
 [  0.11949912  -4.6771529    0.85446513   1.08251345]
 [ -6.56135305 -13.24380041   7.745368    -6.63352692]]
[[11.11616242 -1.47586404]
 [18.01661827 -1.19792418]
 [-8.39948109 -9.02936015]
 [-8.48586139 -6.3778144 ]]
[[-12.58405049]
 [ -4.49174538]]
Activation :sigmoid
Test error is:0.35189396677946844

Activation used:tanh
Learning Rate:0.1
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 1.509130958827904
The final weight vectors are (starting from input to output layers)
[[  329870.45936359   608555.06291154   -56974.60289342   976466.37396967]
 [  272876.75193719   512000.61845066   157429.57827537   649971.37969991]
 [  134130.79633497    82870.99072268   143900.58001693   326107.82617271]
 [    2487.61625419   631902.49455484 -1326981.61357072  1417685.28096496]
 [  230935.4627038    337279.50090683    99266.03965485   492388.51177328]
 [  420449.00947063   910108.53418923 -1800118.04515577  1677367.21176846]]
[[ 1334.54078428 -2357.35400233]
 [-1165.11840924  2721.76459026]
 [ 2864.00750361 -2342.28572481]
 [-2011.07207179  3019.27325479]]
[[-17.23154867]
 [126.13721499]]
Activation :tanh
Test error is:0.4523315754372639

Activation used:relu
Learning Rate:0.1
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.5057801609057405
The final weight vectors are (starting from input to output layers)
[[ 0.654272   -0.00834721 -0.27302263 -0.44879379]
 [ 0.84948163 -0.22602153 -0.01423825 -0.4911238 ]
 [ 0.76993304 -0.23347309 -0.40485057  0.43518992]
 [-0.61826011 -0.76361474  0.67399556  0.48827184]
 [ 0.1810411  -0.51421685  0.24649429  0.27671064]
 [-0.34486111 -0.86502131  0.7610772  -0.08008654]]
[[ 0.52774544 -0.49222276]
 [ 0.18277436 -0.14240968]
 [-0.23579871 -0.74657323]
 [-0.51146667 -0.84131683]]
[[-0.39428339]
 [ 0.4834096 ]]
Activation :relu
Test error is:0.48717140882060417


Activation used:tanh
Learning Rate:0.05
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.4555454820904717
The final weight vectors are (starting from input to output layers)
[[  13970.61805194  -12583.71747639   -4161.36735056 -332039.28730654]
 [  12168.76824246  -10393.94379197   -2797.66573608 -261269.47725796]
 [   1255.439028     -1431.14709882   -1973.51891839  -91198.20454895]
 [  40701.90760617  -31520.35267196    3986.70609569 -404588.08618389]
 [  -1358.89334848   -1994.26910153   -7180.83691933 -208320.3074986 ]
 [  -8308.27413862    6479.48757504  -14741.82989157 -501889.11960644]]
[[   2.27675024 -232.90903788]
 [ -77.94498288 -112.43416044]
 [-211.14008003  -23.96788564]
 [-426.96202701  319.14483939]]
[[23.25193329]
 [13.63875767]]
Activation :tanh
Test error is:0.4297850901225144


Activation used:relu
Learning Rate:0.05
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.5372953636712061
The final weight vectors are (starting from input to output layers)
[[ 0.654272   -0.00834721 -0.27302263 -0.44879379]
 [ 0.84948163 -0.22602153 -0.01423825 -0.4911238 ]
 [ 0.76993304 -0.23347309 -0.40485057  0.43518992]
 [-0.61826011 -0.76361474  0.67399556  0.48827184]
 [ 0.1810411  -0.51421685  0.24649429  0.27671064]
 [-0.34486111 -0.86502131  0.7610772  -0.08008654]]
[[ 0.52774544 -0.49222276]
 [ 0.18277436 -0.14240968]
 [-0.23579871 -0.74657323]
 [-0.51146667 -0.84131683]]
[[-0.39428339]
 [ 0.4834096 ]]
Activation :relu
Test error is:0.4529978784658642

Activation used:sigmoid
Learning Rate:0.2
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.3558588842223898
The final weight vectors are (starting from input to output layers)
[[ -1.70369873  -3.4607148    7.25398783   0.17962604]
 [ -0.36415091  -1.48898713   7.82412172  -0.59922276]
 [ -0.31035686  -1.29678725  -0.07964516   0.2577531 ]
 [-10.11313903  -0.02193887   1.62478789   2.77026362]
 [ -0.54287857  -3.12307734   1.13999958   0.39587437]
 [ -3.0578636  -10.94775331   6.51430712   2.58438034]]
[[ 11.79198816  -1.68725474]
 [ 11.8198043   -2.24324978]
 [-11.73024968  -6.6561177 ]
 [  0.3031546   -5.04191137]]
[[-16.16627204]
 [ -6.67202711]]
Activation :sigmoid
Test error is:0.3505453945763383


Activation used:tanh
Learning Rate:0.2
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 1.5305330719901309
The final weight vectors are (starting from input to output layers)
[[-9.29646267e+07 -9.03411954e+06  1.06847069e+05 -2.87265678e+06]
 [-6.14524477e+07 -5.83324063e+06  3.30149464e+05 -5.31689472e+06]
 [-2.51664602e+07 -2.18829786e+06 -2.15592325e+05 -8.30902722e+04]
 [-1.09770291e+08 -5.68299453e+06  1.86549194e+06 -6.34867595e+06]
 [-5.38779907e+07 -7.38119119e+06 -1.18793405e+06 -2.24820762e+04]
 [-1.38953805e+08 -3.14316408e+05  3.22215562e+06 -9.35404232e+06]]
[[-2011.07336711 10294.66714973]
 [ 4033.52693677  7028.06255032]
 [ 4506.62481514  2327.67251411]
 [  831.25108149  5159.26444808]]
[[117.74359532]
 [ 23.26113443]]
Activation :tanh
Test error is:0.5380301469830567


Activation used:relu
Learning Rate:0.2
No. of nodes in hidden layer 1:4
No.of nodes in hidden layer 2:2
After 1000 iterations, the total error is 0.5057801609057405
The final weight vectors are (starting from input to output layers)
[[ 0.654272   -0.00834721 -0.27302263 -0.44879379]
 [ 0.84948163 -0.22602153 -0.01423825 -0.4911238 ]
 [ 0.76993304 -0.23347309 -0.40485057  0.43518992]
 [-0.61826011 -0.76361474  0.67399556  0.48827184]
 [ 0.1810411  -0.51421685  0.24649429  0.27671064]
 [-0.34486111 -0.86502131  0.7610772  -0.08008654]]
[[ 0.52774544 -0.49222276]
 [ 0.18277436 -0.14240968]
 [-0.23579871 -0.74657323]
 [-0.51146667 -0.84131683]]
[[-0.39428339]
 [ 0.4834096 ]]
Activation :relu
Test error is:0.48717140882060417



